{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d93e6a-106b-4abd-87e7-1243d4c51126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:27.660242Z",
     "iopub.status.busy": "2024-05-30T13:36:27.660075Z",
     "iopub.status.idle": "2024-05-30T13:36:31.462084Z",
     "shell.execute_reply": "2024-05-30T13:36:31.461473Z",
     "shell.execute_reply.started": "2024-05-30T13:36:27.660221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CommitFit\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers accelerate\n",
    "from transformers import AutoTokenizer, AutoModel, EarlyStoppingCallback, AutoModelForSequenceClassification, AutoConfig,Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# !pip install datasets\n",
    "from datasets import load_metric\n",
    "# %pip install evaluate\n",
    "from evaluate import evaluator\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from ipywidgets import FloatProgress\n",
    "import csv\n",
    "from optuna import Trial\n",
    "from typing import Dict, Union, Any\n",
    "import os\n",
    "import sys\n",
    "# notebook_login()\n",
    "\n",
    "csv.field_size_limit(500 * 1024 * 1024)\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "# get pwd\n",
    "notebook_path = os.path.abspath('')\n",
    "\n",
    "# Find the part of the path that contains 'commitFit'\n",
    "commit_fit_path = None\n",
    "for part in notebook_path.split(os.sep):\n",
    "    print(part)\n",
    "    if 'CommitFit' in part:\n",
    "        commit_fit_path = notebook_path.split(part)[0] + part\n",
    "        break\n",
    "\n",
    "if commit_fit_path is None:\n",
    "    raise ValueError(\"Path containing 'commitFit' not found in notebook path.\")\n",
    "\n",
    "# Add commitFit directory to Python path, so we can import moudule from commitfit folder directly\n",
    "if commit_fit_path not in sys.path:\n",
    "    sys.path.append(commit_fit_path)\n",
    "\n",
    "from commitfit import CommitFitModel, CommitFitTrainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef5359f-9526-4d19-a2da-7988dc1ea04f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.463034Z",
     "iopub.status.busy": "2024-05-30T13:36:31.462748Z",
     "iopub.status.idle": "2024-05-30T13:36:31.491563Z",
     "shell.execute_reply": "2024-05-30T13:36:31.490735Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.463016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('D:\\IET software-CC-CL\\Commit Classification\\experiment\\Commit_dataset.csv', encoding=\"cp1252\")\n",
    "\n",
    "# label2id = {'a':'Adaptive','p':'Perfective','c':'Corrective'}\n",
    "# df = df.replace({\"3_labels\": label2id})\n",
    "# df = pd.read_csv(r'dataset.csv',engine=\"python\")\n",
    "# df['text'] = \"['DIFF]\" + df['diff']\n",
    "# # df = df.replace({\"2_labels\": label2id})\n",
    "# print(df)\n",
    "\n",
    "train = pd.read_csv('train.csv',index_col=0)\n",
    "train = train.rename(columns={'3_labels':'label','comment':'text'})\n",
    "train.fillna(0, inplace=True)\n",
    "test = pd.read_csv('test.csv',index_col=0)\n",
    "test = test.rename(columns={'3_labels':'label','comment':'text'})\n",
    "test.fillna(0, inplace=True)\n",
    "print(len(test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26803da1-da52-48a7-8040-70914c05f2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.492467Z",
     "iopub.status.busy": "2024-05-30T13:36:31.492296Z",
     "iopub.status.idle": "2024-05-30T13:36:31.497653Z",
     "shell.execute_reply": "2024-05-30T13:36:31.496862Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.492451Z"
    }
   },
   "outputs": [],
   "source": [
    "train_change_feautre = train.iloc[:, 4:]\n",
    "test_change_feautre = test.iloc[:, 4:]\n",
    "\n",
    "train_code_change = train_change_feautre.values\n",
    "test_code_change = test_change_feautre.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb125ae-f537-4934-bbe2-cbf1e78c96bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.498944Z",
     "iopub.status.busy": "2024-05-30T13:36:31.498497Z",
     "iopub.status.idle": "2024-05-30T13:36:31.501940Z",
     "shell.execute_reply": "2024-05-30T13:36:31.501330Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.498919Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install setfit\n",
    "from commitfit import get_templated_dataset,sample_dataset\n",
    "from datasets import Dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e214dbb-075e-4fbf-adc9-f3533801587e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.502854Z",
     "iopub.status.busy": "2024-05-30T13:36:31.502606Z",
     "iopub.status.idle": "2024-05-30T13:36:31.528753Z",
     "shell.execute_reply": "2024-05-30T13:36:31.528066Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.502832Z"
    }
   },
   "outputs": [],
   "source": [
    "Dataset_train = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8ec7ec-1112-4140-8ccd-516ba9a1b1a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.530820Z",
     "iopub.status.busy": "2024-05-30T13:36:31.530642Z",
     "iopub.status.idle": "2024-05-30T13:36:31.702606Z",
     "shell.execute_reply": "2024-05-30T13:36:31.701791Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.530803Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = get_templated_dataset(Dataset_train, candidate_labels=['Corrective','Adaptive','Perfective'], sample_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ea76cd-69e5-4aa8-bf49-c9e746b63bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.703618Z",
     "iopub.status.busy": "2024-05-30T13:36:31.703452Z",
     "iopub.status.idle": "2024-05-30T13:36:31.709919Z",
     "shell.execute_reply": "2024-05-30T13:36:31.709343Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.703601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['commit_id', 'project', 'text', 'label', 'ADDING_ATTRIBUTE_MODIFIABILITY', 'ADDING_METHOD_OVERRIDABILITY', 'ADDITIONAL_CLASS', 'ADDITIONAL_FUNCTIONALITY', 'ADDITIONAL_OBJECT_STATE', 'ALTERNATIVE_PART_DELETE', 'ALTERNATIVE_PART_INSERT', 'ATTRIBUTE_RENAMING', 'ATTRIBUTE_TYPE_CHANGE', 'CLASS_RENAMING', 'COMMENT_DELETE', 'COMMENT_INSERT', 'COMMENT_MOVE', 'COMMENT_UPDATE', 'CONDITION_EXPRESSION_CHANGE', 'DECREASING_ACCESSIBILITY_CHANGE', 'DOC_DELETE', 'DOC_INSERT', 'DOC_UPDATE', 'INCREASING_ACCESSIBILITY_CHANGE', 'METHOD_RENAMING', 'PARAMETER_DELETE', 'PARAMETER_INSERT', 'PARAMETER_ORDERING_CHANGE', 'PARAMETER_RENAMING', 'PARAMETER_TYPE_CHANGE', 'PARENT_CLASS_CHANGE', 'PARENT_CLASS_DELETE', 'PARENT_CLASS_INSERT', 'PARENT_INTERFACE_CHANGE', 'PARENT_INTERFACE_DELETE', 'PARENT_INTERFACE_INSERT', 'REMOVED_CLASS', 'REMOVED_FUNCTIONALITY', 'REMOVED_OBJECT_STATE', 'REMOVING_ATTRIBUTE_MODIFIABILITY', 'REMOVING_CLASS_DERIVABILITY', 'REMOVING_METHOD_OVERRIDABILITY', 'RETURN_TYPE_CHANGE', 'RETURN_TYPE_DELETE', 'RETURN_TYPE_INSERT', 'STATEMENT_DELETE', 'STATEMENT_INSERT', 'STATEMENT_ORDERING_CHANGE', 'STATEMENT_PARENT_CHANGE', 'STATEMENT_UPDATE', 'add', 'allow', 'bug', 'chang', 'error', 'fail', 'fix', 'implement', 'improv', 'issu', 'method', 'new', 'npe', 'refactor', 'remov', 'report', 'set', 'support', 'test', 'use', 'Contains Bug Fix?', 'Extract Method', 'Inline Method', 'Move Method', 'Move Attribute', 'Pull up Method', 'Pull up Attribute', 'Push Down Method', 'Push Down Attribute', 'Extract Class', 'Extract Subclass', 'Extract Superclass', 'Extract Interface', 'Change Package', 'Extract Variable', 'Inline Variable', 'Parametrize Variable', 'Rename Variable', 'Replace Variable with Attribute', 'Change Variable Type', 'Move and Rename Class', 'Move Class', 'Extract and Move Method', 'Move Source Folder', '__index_level_0__'],\n",
       "    num_rows: 1279\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(train['message'].astype(str).values)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee30affe-0ec9-46a3-bcaa-a1bd9422c939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.710834Z",
     "iopub.status.busy": "2024-05-30T13:36:31.710604Z",
     "iopub.status.idle": "2024-05-30T13:36:31.715167Z",
     "shell.execute_reply": "2024-05-30T13:36:31.714566Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.710811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e38639-cf4b-4762-a1dc-cdc983938388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.716170Z",
     "iopub.status.busy": "2024-05-30T13:36:31.715958Z",
     "iopub.status.idle": "2024-05-30T13:36:31.722566Z",
     "shell.execute_reply": "2024-05-30T13:36:31.721864Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.716150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Corrective    422\n",
       "Perfective    420\n",
       "Adaptive      413\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cf6c110-616d-45da-aa2e-4a5add26b3c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.723466Z",
     "iopub.status.busy": "2024-05-30T13:36:31.723259Z",
     "iopub.status.idle": "2024-05-30T13:36:31.729247Z",
     "shell.execute_reply": "2024-05-30T13:36:31.728555Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.723445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Corrective    181\n",
       "Perfective    180\n",
       "Adaptive      177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77117d87-5292-48f5-b077-74b47ccfd5eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.730115Z",
     "iopub.status.busy": "2024-05-30T13:36:31.729915Z",
     "iopub.status.idle": "2024-05-30T13:36:31.734586Z",
     "shell.execute_reply": "2024-05-30T13:36:31.733862Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.730095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1279"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dca6275a-a567-4963-831c-8dd653341162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.735663Z",
     "iopub.status.busy": "2024-05-30T13:36:31.735459Z",
     "iopub.status.idle": "2024-05-30T13:36:31.739793Z",
     "shell.execute_reply": "2024-05-30T13:36:31.739082Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.735641Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "def compute_metrics(y_pred, y_test):\n",
    "    # print(y_pred,y_test)\n",
    "    # classification_report = metrics.classification_report(y_test,y_pred)\n",
    "    accuracy_score = metrics.accuracy_score(y_test,y_pred)\n",
    "    precision_score = metrics.precision_score(y_test,y_pred, average='weighted')\n",
    "    recall_score = metrics.recall_score(y_test,y_pred,average='weighted')\n",
    "    f1_score = metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "\n",
    "    # return {\"classification_report\": classification_report}\n",
    "    return {\"precision\": precision_score,\"recall\": recall_score, \"f1\":f1_score, \"accuracy\": accuracy_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49e32d66-2fc2-4a53-bae1-13f8d67c5b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.740629Z",
     "iopub.status.busy": "2024-05-30T13:36:31.740434Z",
     "iopub.status.idle": "2024-05-30T13:36:31.744752Z",
     "shell.execute_reply": "2024-05-30T13:36:31.744066Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.740609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['commit_id', 'project', 'text', 'label', 'ADDING_ATTRIBUTE_MODIFIABILITY', 'ADDING_METHOD_OVERRIDABILITY', 'ADDITIONAL_CLASS', 'ADDITIONAL_FUNCTIONALITY', 'ADDITIONAL_OBJECT_STATE', 'ALTERNATIVE_PART_DELETE', 'ALTERNATIVE_PART_INSERT', 'ATTRIBUTE_RENAMING', 'ATTRIBUTE_TYPE_CHANGE', 'CLASS_RENAMING', 'COMMENT_DELETE', 'COMMENT_INSERT', 'COMMENT_MOVE', 'COMMENT_UPDATE', 'CONDITION_EXPRESSION_CHANGE', 'DECREASING_ACCESSIBILITY_CHANGE', 'DOC_DELETE', 'DOC_INSERT', 'DOC_UPDATE', 'INCREASING_ACCESSIBILITY_CHANGE', 'METHOD_RENAMING', 'PARAMETER_DELETE', 'PARAMETER_INSERT', 'PARAMETER_ORDERING_CHANGE', 'PARAMETER_RENAMING', 'PARAMETER_TYPE_CHANGE', 'PARENT_CLASS_CHANGE', 'PARENT_CLASS_DELETE', 'PARENT_CLASS_INSERT', 'PARENT_INTERFACE_CHANGE', 'PARENT_INTERFACE_DELETE', 'PARENT_INTERFACE_INSERT', 'REMOVED_CLASS', 'REMOVED_FUNCTIONALITY', 'REMOVED_OBJECT_STATE', 'REMOVING_ATTRIBUTE_MODIFIABILITY', 'REMOVING_CLASS_DERIVABILITY', 'REMOVING_METHOD_OVERRIDABILITY', 'RETURN_TYPE_CHANGE', 'RETURN_TYPE_DELETE', 'RETURN_TYPE_INSERT', 'STATEMENT_DELETE', 'STATEMENT_INSERT', 'STATEMENT_ORDERING_CHANGE', 'STATEMENT_PARENT_CHANGE', 'STATEMENT_UPDATE', 'add', 'allow', 'bug', 'chang', 'error', 'fail', 'fix', 'implement', 'improv', 'issu', 'method', 'new', 'npe', 'refactor', 'remov', 'report', 'set', 'support', 'test', 'use', 'Contains Bug Fix?', 'Extract Method', 'Inline Method', 'Move Method', 'Move Attribute', 'Pull up Method', 'Pull up Attribute', 'Push Down Method', 'Push Down Attribute', 'Extract Class', 'Extract Subclass', 'Extract Superclass', 'Extract Interface', 'Change Package', 'Extract Variable', 'Inline Variable', 'Parametrize Variable', 'Rename Variable', 'Replace Variable with Attribute', 'Change Variable Type', 'Move and Rename Class', 'Move Class', 'Extract and Move Method', 'Move Source Folder', '__index_level_0__'],\n",
       "    num_rows: 1279\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c52074-c55f-4218-bc87-cdbc6e36a993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.745636Z",
     "iopub.status.busy": "2024-05-30T13:36:31.745435Z",
     "iopub.status.idle": "2024-05-30T13:36:31.763541Z",
     "shell.execute_reply": "2024-05-30T13:36:31.762884Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.745616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_id</th>\n",
       "      <th>project</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>ADDING_ATTRIBUTE_MODIFIABILITY</th>\n",
       "      <th>ADDING_METHOD_OVERRIDABILITY</th>\n",
       "      <th>ADDITIONAL_CLASS</th>\n",
       "      <th>ADDITIONAL_FUNCTIONALITY</th>\n",
       "      <th>ADDITIONAL_OBJECT_STATE</th>\n",
       "      <th>ALTERNATIVE_PART_DELETE</th>\n",
       "      <th>...</th>\n",
       "      <th>Extract Variable</th>\n",
       "      <th>Inline Variable</th>\n",
       "      <th>Parametrize Variable</th>\n",
       "      <th>Rename Variable</th>\n",
       "      <th>Replace Variable with Attribute</th>\n",
       "      <th>Change Variable Type</th>\n",
       "      <th>Move and Rename Class</th>\n",
       "      <th>Move Class</th>\n",
       "      <th>Extract and Move Method</th>\n",
       "      <th>Move Source Folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0950c46beda335819928585f1262dfe1dca78a0b</td>\n",
       "      <td>ReactiveX-RxJava</td>\n",
       "      <td>Trying to extend the Scheduler interface accor...</td>\n",
       "      <td>Adaptive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>869a002cae63a4e8ab52ec7f2d15d5a2cfbe0c02</td>\n",
       "      <td>drools</td>\n",
       "      <td>[DROOLS-839] fix LogicTransformer with Accumul...</td>\n",
       "      <td>Corrective</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>3ca94cabb68789cb20e37e0c9ecea7acc8b9487e</td>\n",
       "      <td>Valadoc</td>\n",
       "      <td>libvaladoc/html: Add \"All known members inheri...</td>\n",
       "      <td>Adaptive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>171accb43d709bd3960187686afbdf68f5239644</td>\n",
       "      <td>aeshell$aesh</td>\n",
       "      <td>[AESH-316] - print warning instead of exceptio...</td>\n",
       "      <td>Adaptive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>5b91442a260b42e3d47ef91a53015f2d0958a683</td>\n",
       "      <td>Delta Spike</td>\n",
       "      <td>remove unused private field\\n</td>\n",
       "      <td>Perfective</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>f2757568dac2a6473f054101f80ac2b8f291ce4e</td>\n",
       "      <td>Vala</td>\n",
       "      <td>glib-2.0: add GLib.HashTable.foreach\\n\\nFixes ...</td>\n",
       "      <td>Adaptive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>16cb7d8d59add7b3ef513bba0de6a4fc07e3bc52</td>\n",
       "      <td>aeshell$aesh</td>\n",
       "      <td>search is more complete, support forward/rever...</td>\n",
       "      <td>Adaptive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>14c657d448b6dd743806c4df2a321d58f4e0618e</td>\n",
       "      <td>kotlin</td>\n",
       "      <td>Extract Function: Consider reference \"broken\" ...</td>\n",
       "      <td>Corrective</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>02668af08bebc5266b321ab1df2f45dfe656c813</td>\n",
       "      <td>duracloud$duracloud</td>\n",
       "      <td>First part of https://jira.duraspace.org/brows...</td>\n",
       "      <td>Perfective</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>e86d48730c64d10ba2a838e5663f9ab7a698c9c6</td>\n",
       "      <td>hadoop</td>\n",
       "      <td>HADOOP-7187. Fix socket leak in GangliaContext...</td>\n",
       "      <td>Corrective</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     commit_id              project  \\\n",
       "1     0950c46beda335819928585f1262dfe1dca78a0b     ReactiveX-RxJava   \n",
       "498   869a002cae63a4e8ab52ec7f2d15d5a2cfbe0c02               drools   \n",
       "1010  3ca94cabb68789cb20e37e0c9ecea7acc8b9487e              Valadoc   \n",
       "1583  171accb43d709bd3960187686afbdf68f5239644         aeshell$aesh   \n",
       "1369  5b91442a260b42e3d47ef91a53015f2d0958a683          Delta Spike   \n",
       "...                                        ...                  ...   \n",
       "1411  f2757568dac2a6473f054101f80ac2b8f291ce4e                 Vala   \n",
       "1574  16cb7d8d59add7b3ef513bba0de6a4fc07e3bc52         aeshell$aesh   \n",
       "597   14c657d448b6dd743806c4df2a321d58f4e0618e               kotlin   \n",
       "1712  02668af08bebc5266b321ab1df2f45dfe656c813  duracloud$duracloud   \n",
       "373   e86d48730c64d10ba2a838e5663f9ab7a698c9c6               hadoop   \n",
       "\n",
       "                                                   text       label  \\\n",
       "1     Trying to extend the Scheduler interface accor...    Adaptive   \n",
       "498   [DROOLS-839] fix LogicTransformer with Accumul...  Corrective   \n",
       "1010  libvaladoc/html: Add \"All known members inheri...    Adaptive   \n",
       "1583  [AESH-316] - print warning instead of exceptio...    Adaptive   \n",
       "1369                      remove unused private field\\n  Perfective   \n",
       "...                                                 ...         ...   \n",
       "1411  glib-2.0: add GLib.HashTable.foreach\\n\\nFixes ...    Adaptive   \n",
       "1574  search is more complete, support forward/rever...    Adaptive   \n",
       "597   Extract Function: Consider reference \"broken\" ...  Corrective   \n",
       "1712  First part of https://jira.duraspace.org/brows...  Perfective   \n",
       "373   HADOOP-7187. Fix socket leak in GangliaContext...  Corrective   \n",
       "\n",
       "      ADDING_ATTRIBUTE_MODIFIABILITY  ADDING_METHOD_OVERRIDABILITY  \\\n",
       "1                                  0                             0   \n",
       "498                                0                             0   \n",
       "1010                               0                             0   \n",
       "1583                               0                             0   \n",
       "1369                               0                             0   \n",
       "...                              ...                           ...   \n",
       "1411                               0                             0   \n",
       "1574                               0                             0   \n",
       "597                                0                             0   \n",
       "1712                               0                             0   \n",
       "373                                0                             0   \n",
       "\n",
       "      ADDITIONAL_CLASS  ADDITIONAL_FUNCTIONALITY  ADDITIONAL_OBJECT_STATE  \\\n",
       "1                    0                         1                        0   \n",
       "498                  1                         9                        1   \n",
       "1010                 0                         0                        0   \n",
       "1583                 0                         1                        0   \n",
       "1369                 0                         0                        0   \n",
       "...                ...                       ...                      ...   \n",
       "1411                 0                         0                        0   \n",
       "1574                 0                         1                        1   \n",
       "597                  0                         1                        0   \n",
       "1712                 0                         1                        0   \n",
       "373                  0                         1                        0   \n",
       "\n",
       "      ALTERNATIVE_PART_DELETE  ...  Extract Variable  Inline Variable  \\\n",
       "1                           0  ...                 0                0   \n",
       "498                         1  ...                 0                0   \n",
       "1010                        0  ...                 0                0   \n",
       "1583                        0  ...                 1                0   \n",
       "1369                        0  ...                 0                0   \n",
       "...                       ...  ...               ...              ...   \n",
       "1411                        0  ...                 0                0   \n",
       "1574                        0  ...                 0                0   \n",
       "597                         0  ...                 0                0   \n",
       "1712                        0  ...                 0                0   \n",
       "373                         0  ...                 0                0   \n",
       "\n",
       "      Parametrize Variable  Rename Variable  Replace Variable with Attribute  \\\n",
       "1                        0                0                                0   \n",
       "498                      0                1                                0   \n",
       "1010                     0                0                                0   \n",
       "1583                     0                0                                0   \n",
       "1369                     0                0                                0   \n",
       "...                    ...              ...                              ...   \n",
       "1411                     0                0                                0   \n",
       "1574                     0                0                                0   \n",
       "597                      0                0                                0   \n",
       "1712                     0                1                                0   \n",
       "373                      0                0                                0   \n",
       "\n",
       "      Change Variable Type  Move and Rename Class  Move Class  \\\n",
       "1                        0                      0           0   \n",
       "498                      1                      0           0   \n",
       "1010                     0                      0           0   \n",
       "1583                     0                      0           0   \n",
       "1369                     0                      0           0   \n",
       "...                    ...                    ...         ...   \n",
       "1411                     0                      0           0   \n",
       "1574                     0                      0           0   \n",
       "597                      0                      0           0   \n",
       "1712                     0                      0           1   \n",
       "373                      0                      0           0   \n",
       "\n",
       "      Extract and Move Method  Move Source Folder  \n",
       "1                           0                   0  \n",
       "498                         0                   0  \n",
       "1010                        0                   0  \n",
       "1583                        0                   0  \n",
       "1369                        0                   0  \n",
       "...                       ...                 ...  \n",
       "1411                        0                   0  \n",
       "1574                        0                   0  \n",
       "597                         0                   0  \n",
       "1712                        0                   0  \n",
       "373                         0                   0  \n",
       "\n",
       "[1255 rows x 94 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ede869-1587-4e42-8879-e819e5961dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.764139Z",
     "iopub.status.busy": "2024-05-30T13:36:31.763995Z",
     "iopub.status.idle": "2024-05-30T13:36:31.767176Z",
     "shell.execute_reply": "2024-05-30T13:36:31.766528Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.764124Z"
    }
   },
   "outputs": [],
   "source": [
    "model_id = \"../../sentence-transformers/all-roberta-large-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6501389-0c86-442d-85cf-f04ad146703f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.767855Z",
     "iopub.status.busy": "2024-05-30T13:36:31.767703Z",
     "iopub.status.idle": "2024-05-30T13:36:31.772549Z",
     "shell.execute_reply": "2024-05-30T13:36:31.771634Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.767838Z"
    }
   },
   "outputs": [],
   "source": [
    "def hp_space(trial: Trial) -> Dict[str, Union[float, int, str]]:\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-3, log=True),\n",
    "        # \"num_epochs\": trial.suggest_int(\"num_epochs\", 1, 3),\n",
    "        # \"batch_size\": trial.suggest_categorical(\"batch_size\", [8, 12, 16]),\n",
    "        # \"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
    "        # \"num_iterations\": trial.suggest_int(\"num_iterations\", 10, 20),\n",
    "        # \"solver\": trial.suggest_categorical(\"solver\", [\"newton-cg\", \"lbfgs\", \"liblinear\"]),\n",
    "    }\n",
    "def model_init(params: Dict[str, Any]) -> CommitFitModel:\n",
    "    params = params or {}\n",
    "    # learning_rate = params.get(\"learning_rate\")\n",
    "    # num_iterations = params.get(\"num_iterations\", 20)\n",
    "    # solver = params.get(\"solver\", \"liblinear\")\n",
    "    # params = {\n",
    "    #     \"head_params\": {\n",
    "    #         # \"max_iter\": num_iterations,\n",
    "    #         # \"solver\": solver,\n",
    "    #     }\n",
    "    # }\n",
    "    return CommitFitModel.from_pretrained(model_id, **params)\n",
    "def my_compute_objective(metrics):\n",
    "    print('+++++++++++',metrics)\n",
    "    return  metrics['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2244f079-c2b8-4e01-aca4-f68e7ce8accb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T13:36:31.773654Z",
     "iopub.status.busy": "2024-05-30T13:36:31.773381Z",
     "iopub.status.idle": "2024-05-30T18:34:46.311467Z",
     "shell.execute_reply": "2024-05-30T18:34:46.310540Z",
     "shell.execute_reply.started": "2024-05-30T13:36:31.773626Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "[I 2024-05-30 21:36:33,982] A new study created in memory with name: no-name-5be74e56-28a9-401c-a83e-dfa3f22895bf\n",
      "Trial: {'learning_rate': 1.6739145856014385e-06}\n",
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4460d927f54aecbb05244ca842fd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b17121d2bf4e86bb50f3f8dc3b596b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de98a4765c14c57a11c61aaeddf7a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-05-30 22:06:23,098] Trial 0 finished with value: 0.8085501858736059 and parameters: {'learning_rate': 1.6739145856014385e-06}. Best is trial 0 with value: 0.8085501858736059.\n",
      "Trial: {'learning_rate': 0.0002650834119483927}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.8092727738563398, 'recall': 0.8085501858736059, 'f1': 0.8085274768395471, 'accuracy': 0.8085501858736059}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2121fed98a54a6f92469c5fe31558af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514a236c808049cdb744d24e04347c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c642d31bbd46c5a352cc599ebcdd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "***** Running evaluation *****\n",
      "[I 2024-05-30 22:36:12,678] Trial 1 finished with value: 0.6747211895910781 and parameters: {'learning_rate': 0.0002650834119483927}. Best is trial 0 with value: 0.8085501858736059.\n",
      "Trial: {'learning_rate': 5.689594177062016e-06}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.6862624654976469, 'recall': 0.6747211895910781, 'f1': 0.673098503687807, 'accuracy': 0.6747211895910781}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fe8324715346dd857159246922931b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3b186ef0bf4b93918ca75c1d807d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ab9f6a3e564d4c9f8f1039d4cf6770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-05-30 23:06:02,795] Trial 2 finished with value: 0.8178438661710037 and parameters: {'learning_rate': 5.689594177062016e-06}. Best is trial 2 with value: 0.8178438661710037.\n",
      "Trial: {'learning_rate': 0.0003562354328946638}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.8183300912446904, 'recall': 0.8178438661710037, 'f1': 0.8178608285805725, 'accuracy': 0.8178438661710037}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6961d1044ed47efa73c5effbe3ea5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dacac2ea34049fe9fa441ea6da865c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2eca6c557b4c6995f0a09bed69b827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "***** Running evaluation *****\n",
      "[I 2024-05-30 23:35:51,687] Trial 3 finished with value: 0.6747211895910781 and parameters: {'learning_rate': 0.0003562354328946638}. Best is trial 2 with value: 0.8178438661710037.\n",
      "Trial: {'learning_rate': 1.68943052050063e-06}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.6862624654976469, 'recall': 0.6747211895910781, 'f1': 0.673098503687807, 'accuracy': 0.6747211895910781}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706685405bfa49a68b6b07e7eaa2e4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b293c4fe324d2f9aa0f293ba2e0a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f9d945f49e4a03924458b6468594c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-05-31 00:05:41,413] Trial 4 finished with value: 0.8104089219330854 and parameters: {'learning_rate': 1.68943052050063e-06}. Best is trial 2 with value: 0.8178438661710037.\n",
      "Trial: {'learning_rate': 6.49835890209835e-05}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.8110341938917629, 'recall': 0.8104089219330854, 'f1': 0.8103362468759224, 'accuracy': 0.8104089219330854}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9e95c4facf4a2d95d6c8a0d6db496e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10205abb22aa472fac563d6294e98087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6976a34ed0465ea7d929f757581317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-05-31 00:35:32,494] Trial 5 finished with value: 0.8215613382899628 and parameters: {'learning_rate': 6.49835890209835e-05}. Best is trial 5 with value: 0.8215613382899628.\n",
      "Trial: {'learning_rate': 1.6519638064427163e-05}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.8233958460948287, 'recall': 0.8215613382899628, 'f1': 0.8211340470832682, 'accuracy': 0.8215613382899628}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d75d2ed562f4d5d9929c94e77be7d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4fdc5e25d34a55a61db7b4aa73e298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b98a63c3e346f8be73fa493b1bd955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-05-31 01:05:22,606] Trial 6 finished with value: 0.8178438661710037 and parameters: {'learning_rate': 1.6519638064427163e-05}. Best is trial 5 with value: 0.8215613382899628.\n",
      "Trial: {'learning_rate': 0.00036189292737384953}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.8186130288466502, 'recall': 0.8178438661710037, 'f1': 0.8176976375782328, 'accuracy': 0.8178438661710037}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220a213bdd3144ff8a0d68a7d8804fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7105565c0a754f77a79b7dd8e40c3231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1158b11a9445eda80c5d7774e849f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "***** Running evaluation *****\n",
      "[I 2024-05-31 01:35:10,001] Trial 7 finished with value: 0.6747211895910781 and parameters: {'learning_rate': 0.00036189292737384953}. Best is trial 5 with value: 0.8215613382899628.\n",
      "Trial: {'learning_rate': 6.349131140494384e-05}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.6862624654976469, 'recall': 0.6747211895910781, 'f1': 0.673098503687807, 'accuracy': 0.6747211895910781}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aa759b5e4a4c67aca9bef4a7458dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38af60e30c7a4b86a6dbc33599fdeedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba487607f3d41af821573fc18d6fbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n",
      "[I 2024-05-31 02:04:59,392] Trial 8 finished with value: 0.828996282527881 and parameters: {'learning_rate': 6.349131140494384e-05}. Best is trial 8 with value: 0.828996282527881.\n",
      "Trial: {'learning_rate': 0.0009677420578413232}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.8300888484661556, 'recall': 0.828996282527881, 'f1': 0.8291308849134713, 'accuracy': 0.828996282527881}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93baf3495034df9a5c42e763b7a76ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345c8afe235f4d2199a33700ab4200df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f75c6b4feb640d1bb468f88f9aab3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "***** Running evaluation *****\n",
      "[I 2024-05-31 02:34:46,307] Trial 9 finished with value: 0.6747211895910781 and parameters: {'learning_rate': 0.0009677420578413232}. Best is trial 8 with value: 0.828996282527881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++ {'precision': 0.6862624654976469, 'recall': 0.6747211895910781, 'f1': 0.673098503687807, 'accuracy': 0.6747211895910781}\n"
     ]
    }
   ],
   "source": [
    "trainer = CommitFitTrainer(\n",
    "    train_dataset=train_dataset,\n",
    "    train_code_change = train_code_change,\n",
    "    test_code_change = test_code_change,\n",
    "    eval_dataset=test_dataset,\n",
    "    model_init=model_init,\n",
    "    metric = compute_metrics,\n",
    "    num_iterations=20,\n",
    "    num_epochs=1\n",
    ")\n",
    "best_run = trainer.hyperparameter_search(direction=\"maximize\", hp_space=hp_space, compute_objective=my_compute_objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffc22a73-c0cc-42a5-95f1-0dd2fac75549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T18:34:46.312692Z",
     "iopub.status.busy": "2024-05-30T18:34:46.312464Z",
     "iopub.status.idle": "2024-05-30T18:34:46.317652Z",
     "shell.execute_reply": "2024-05-30T18:34:46.317038Z",
     "shell.execute_reply.started": "2024-05-30T18:34:46.312674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='8', objective=0.828996282527881, hyperparameters={'learning_rate': 6.349131140494384e-05}, backend=<optuna.study.study.Study object at 0x7f798ec89490>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40cfde46-c7d5-4446-8b53-7ad4dc8edb66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T18:34:46.318468Z",
     "iopub.status.busy": "2024-05-30T18:34:46.318267Z",
     "iopub.status.idle": "2024-05-30T18:34:46.322388Z",
     "shell.execute_reply": "2024-05-30T18:34:46.321877Z",
     "shell.execute_reply.started": "2024-05-30T18:34:46.318446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 6.349131140494384e-05}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae735a8b-c672-4dce-822c-61330c34481b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T18:34:46.323329Z",
     "iopub.status.busy": "2024-05-30T18:34:46.323127Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found in /CommitFit/sentence-transformers/all-roberta-large-v1, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a16dd2bcee4238a2a761af93e1ff7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 51160\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 3198\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4ed90190e445d189ab94e89248837b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc91ea028ff646fe94b59fb5d09065b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.apply_hyperparameters(best_run.hyperparameters, final_model=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166dcf9b-a0bd-4b60-854c-c6535c22a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_metrics = trainer.evaluate()\n",
    "fewshot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21aba7-66cd-4762-b5d4-6d27650bba7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
