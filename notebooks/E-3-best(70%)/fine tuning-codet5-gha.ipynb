{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:56:28.204718Z",
     "iopub.status.busy": "2025-12-09T02:56:28.204370Z",
     "iopub.status.idle": "2025-12-09T02:56:28.208721Z",
     "shell.execute_reply": "2025-12-09T02:56:28.207892Z",
     "shell.execute_reply.started": "2025-12-09T02:56:28.204683Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -q evaluate\n",
    "# !pip install -q rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:56:28.209762Z",
     "iopub.status.busy": "2025-12-09T02:56:28.209456Z",
     "iopub.status.idle": "2025-12-09T02:56:32.540747Z",
     "shell.execute_reply": "2025-12-09T02:56:32.540090Z",
     "shell.execute_reply.started": "2025-12-09T02:56:28.209731Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset,DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,T5Tokenizer,T5ForConditionalGeneration\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer,  DataCollatorForTokenClassification\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load flan-t5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:56:32.541524Z",
     "iopub.status.busy": "2025-12-09T02:56:32.541192Z",
     "iopub.status.idle": "2025-12-09T02:56:33.258470Z",
     "shell.execute_reply": "2025-12-09T02:56:33.258057Z",
     "shell.execute_reply.started": "2025-12-09T02:56:32.541511Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the tokenizer, model, and data collator\n",
    "MODEL_NAME = \"/root/autodl-tmp/models/codet5-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:56:33.259094Z",
     "iopub.status.busy": "2025-12-09T02:56:33.258952Z",
     "iopub.status.idle": "2025-12-09T02:56:33.626142Z",
     "shell.execute_reply": "2025-12-09T02:56:33.625513Z",
     "shell.execute_reply.started": "2025-12-09T02:56:33.259082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>commit</th>\n",
       "      <th>labels</th>\n",
       "      <th>msgs</th>\n",
       "      <th>diffs</th>\n",
       "      <th>feature</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ponsonio</th>\n",
       "      <td>RxJava</td>\n",
       "      <td>0531b8bff5c14d9504beefb4ad47f473e3a22932</td>\n",
       "      <td>Perfective</td>\n",
       "      <td>Change hasException to hasThrowable--</td>\n",
       "      <td>diff --git a/rxjava-core/src/main/java/rx/Noti...</td>\n",
       "      <td>[1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Change hasException to hasThrowable--diff --gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ponsonio</th>\n",
       "      <td>RxJava</td>\n",
       "      <td>0950c46beda335819928585f1262dfe1dca78a0b</td>\n",
       "      <td>Adaptive</td>\n",
       "      <td>Trying to extend the Scheduler interface accor...</td>\n",
       "      <td>diff --git a/rxjava-core/src/main/java/rx/Sche...</td>\n",
       "      <td>[2, 44, 0, 0, 30, 0, 0, 1, 18, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Trying to extend the Scheduler interface accor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ponsonio</th>\n",
       "      <td>RxJava</td>\n",
       "      <td>0f92fdd8e6422d5b79c610a7fd8409d222315a49</td>\n",
       "      <td>Adaptive</td>\n",
       "      <td>RunAsync method for outputting multiple values--</td>\n",
       "      <td>diff --git a/rxjava-contrib/rxjava-async-util/...</td>\n",
       "      <td>[2, 53, 0, 0, 42, 0, 0, 1, 45, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>RunAsync method for outputting multiple values...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ponsonio</th>\n",
       "      <td>RxJava</td>\n",
       "      <td>100f571c9a2835d5a30a55374b9be74c147e031f</td>\n",
       "      <td>Corrective</td>\n",
       "      <td>forEach with Action1 but not Observer--I re-re...</td>\n",
       "      <td>diff --git a/language-adaptors/rxjava-groovy/s...</td>\n",
       "      <td>[1, 5, 122, 9, 10, 9, 4, 1, 5, 18, 2, 0, 0, 0,...</td>\n",
       "      <td>forEach with Action1 but not Observer--I re-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ponsonio</th>\n",
       "      <td>RxJava</td>\n",
       "      <td>191f023cf5253ea90647bc091dcaf55ccdce81cc</td>\n",
       "      <td>Corrective</td>\n",
       "      <td>1.x: Fix Completable swallows- OnErrorNotImple...</td>\n",
       "      <td>diff --git a/src/main/java/rx/Completable.java...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 1, 21, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1.x: Fix Completable swallows- OnErrorNotImple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jenkinsci</th>\n",
       "      <td>clearcase-plugin</td>\n",
       "      <td>51e9da224f80254476a7dc446bca817b505381d8</td>\n",
       "      <td>Perfective</td>\n",
       "      <td>Use a temporary file to decrease memory consum...</td>\n",
       "      <td>diff --git a/src/main/java/hudson/plugins/clea...</td>\n",
       "      <td>[2, 12, 0, 4, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>Use a temporary file to decrease memory consum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jexp</th>\n",
       "      <td>batch-import</td>\n",
       "      <td>609d6c4b1eea2c33d9fb950fcbb9ba9dc1f80fc3</td>\n",
       "      <td>Perfective</td>\n",
       "      <td>added a more memory efficient structure for st...</td>\n",
       "      <td>diff --git a/src/main/java/org/neo4j/batchimpo...</td>\n",
       "      <td>[10, 159, 29, 35, 9, 2, 1, 5, 106, 0, 4, 8, 0,...</td>\n",
       "      <td>added a more memory efficient structure for st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdiv</th>\n",
       "      <td>hdiv</td>\n",
       "      <td>19b650c78a1c76f4fd90274d7f163f863c0d39e4</td>\n",
       "      <td>Perfective</td>\n",
       "      <td>Memory and performance optimizations</td>\n",
       "      <td>diff --git a/hdiv-config/src/main/java/org/hdi...</td>\n",
       "      <td>[31, 302, 131, 140, 170, 89, 53, 7, 88, 14, 17...</td>\n",
       "      <td>Memory and performance optimizationsdiff --git...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casidiablo</th>\n",
       "      <td>persistence</td>\n",
       "      <td>d7bf95159df37a3d338ca267dddd3d26b38ec37c</td>\n",
       "      <td>Perfective</td>\n",
       "      <td>Now it is possible to specify the sqlite open ...</td>\n",
       "      <td>diff --git a/pom.xml b/pom.xml\\nindex 394263b....</td>\n",
       "      <td>[5, 57, 20, 9, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Now it is possible to specify the sqlite open ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jhy</th>\n",
       "      <td>jsoup</td>\n",
       "      <td>d6fd1637307f6b088eb226c3f979085725530f32</td>\n",
       "      <td>Perfective</td>\n",
       "      <td>Performance improvment for Element.text</td>\n",
       "      <td>diff --git a/src/main/java/org/jsoup/helper/St...</td>\n",
       "      <td>[3, 11, 11, 9, 13, 0, 0, 1, 0, 8, 0, 0, 1, 0, ...</td>\n",
       "      <td>Performance improvment for Element.textdiff --...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1781 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        repo                                    commit  \\\n",
       "user                                                                     \n",
       "ponsonio              RxJava  0531b8bff5c14d9504beefb4ad47f473e3a22932   \n",
       "ponsonio              RxJava  0950c46beda335819928585f1262dfe1dca78a0b   \n",
       "ponsonio              RxJava  0f92fdd8e6422d5b79c610a7fd8409d222315a49   \n",
       "ponsonio              RxJava  100f571c9a2835d5a30a55374b9be74c147e031f   \n",
       "ponsonio              RxJava  191f023cf5253ea90647bc091dcaf55ccdce81cc   \n",
       "...                      ...                                       ...   \n",
       "jenkinsci   clearcase-plugin  51e9da224f80254476a7dc446bca817b505381d8   \n",
       "jexp            batch-import  609d6c4b1eea2c33d9fb950fcbb9ba9dc1f80fc3   \n",
       "hdiv                    hdiv  19b650c78a1c76f4fd90274d7f163f863c0d39e4   \n",
       "casidiablo       persistence  d7bf95159df37a3d338ca267dddd3d26b38ec37c   \n",
       "jhy                    jsoup  d6fd1637307f6b088eb226c3f979085725530f32   \n",
       "\n",
       "                labels                                               msgs  \\\n",
       "user                                                                        \n",
       "ponsonio    Perfective              Change hasException to hasThrowable--   \n",
       "ponsonio      Adaptive  Trying to extend the Scheduler interface accor...   \n",
       "ponsonio      Adaptive   RunAsync method for outputting multiple values--   \n",
       "ponsonio    Corrective  forEach with Action1 but not Observer--I re-re...   \n",
       "ponsonio    Corrective  1.x: Fix Completable swallows- OnErrorNotImple...   \n",
       "...                ...                                                ...   \n",
       "jenkinsci   Perfective  Use a temporary file to decrease memory consum...   \n",
       "jexp        Perfective  added a more memory efficient structure for st...   \n",
       "hdiv        Perfective               Memory and performance optimizations   \n",
       "casidiablo  Perfective  Now it is possible to specify the sqlite open ...   \n",
       "jhy         Perfective            Performance improvment for Element.text   \n",
       "\n",
       "                                                        diffs  \\\n",
       "user                                                            \n",
       "ponsonio    diff --git a/rxjava-core/src/main/java/rx/Noti...   \n",
       "ponsonio    diff --git a/rxjava-core/src/main/java/rx/Sche...   \n",
       "ponsonio    diff --git a/rxjava-contrib/rxjava-async-util/...   \n",
       "ponsonio    diff --git a/language-adaptors/rxjava-groovy/s...   \n",
       "ponsonio    diff --git a/src/main/java/rx/Completable.java...   \n",
       "...                                                       ...   \n",
       "jenkinsci   diff --git a/src/main/java/hudson/plugins/clea...   \n",
       "jexp        diff --git a/src/main/java/org/neo4j/batchimpo...   \n",
       "hdiv        diff --git a/hdiv-config/src/main/java/org/hdi...   \n",
       "casidiablo  diff --git a/pom.xml b/pom.xml\\nindex 394263b....   \n",
       "jhy         diff --git a/src/main/java/org/jsoup/helper/St...   \n",
       "\n",
       "                                                      feature  \\\n",
       "user                                                            \n",
       "ponsonio    [1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "ponsonio    [2, 44, 0, 0, 30, 0, 0, 1, 18, 0, 0, 0, 0, 0, ...   \n",
       "ponsonio    [2, 53, 0, 0, 42, 0, 0, 1, 45, 1, 0, 0, 0, 0, ...   \n",
       "ponsonio    [1, 5, 122, 9, 10, 9, 4, 1, 5, 18, 2, 0, 0, 0,...   \n",
       "ponsonio    [1, 1, 0, 0, 0, 0, 0, 1, 21, 0, 0, 0, 0, 0, 0,...   \n",
       "...                                                       ...   \n",
       "jenkinsci   [2, 12, 0, 4, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "jexp        [10, 159, 29, 35, 9, 2, 1, 5, 106, 0, 4, 8, 0,...   \n",
       "hdiv        [31, 302, 131, 140, 170, 89, 53, 7, 88, 14, 17...   \n",
       "casidiablo  [5, 57, 20, 9, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "jhy         [3, 11, 11, 9, 13, 0, 0, 1, 0, 8, 0, 0, 1, 0, ...   \n",
       "\n",
       "                                                         text  \n",
       "user                                                           \n",
       "ponsonio    Change hasException to hasThrowable--diff --gi...  \n",
       "ponsonio    Trying to extend the Scheduler interface accor...  \n",
       "ponsonio    RunAsync method for outputting multiple values...  \n",
       "ponsonio    forEach with Action1 but not Observer--I re-re...  \n",
       "ponsonio    1.x: Fix Completable swallows- OnErrorNotImple...  \n",
       "...                                                       ...  \n",
       "jenkinsci   Use a temporary file to decrease memory consum...  \n",
       "jexp        added a more memory efficient structure for st...  \n",
       "hdiv        Memory and performance optimizationsdiff --git...  \n",
       "casidiablo  Now it is possible to specify the sqlite open ...  \n",
       "jhy         Performance improvment for Element.textdiff --...  \n",
       "\n",
       "[1781 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'/root/autodl-tmp/CommitFit/dataset/Ghadhab/dataset.csv', index_col=0, encoding='utf_8_sig')\n",
    "# df.fillna('', inplace=True)\n",
    "# label2id={'Adaptive':0, 'Corrective':1, 'Perfective':2}\n",
    "# df = df.rename(columns={'labels':'label','msgs':'message','diffs':'diff'})\n",
    "# df = df.replace({\"labels\": label2id})\n",
    "# df = df['diffs']\n",
    "# # print(df)\n",
    "df['text'] = df['msgs'] + df['diffs']\n",
    "df\n",
    "# test_sample = df.sample(n=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:56:33.626886Z",
     "iopub.status.busy": "2025-12-09T02:56:33.626737Z",
     "iopub.status.idle": "2025-12-09T02:56:34.178256Z",
     "shell.execute_reply": "2025-12-09T02:56:34.177570Z",
     "shell.execute_reply.started": "2025-12-09T02:56:33.626873Z"
    }
   },
   "outputs": [],
   "source": [
    "full_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# 1) train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "first_split = full_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "train_dataset = first_split[\"train\"]      # ~70%\n",
    "test_tmp  = first_split[\"test\"]       # ~30%\n",
    "\n",
    "# 2) test_data, val_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "second_split = test_tmp.train_test_split(test_size=0.5, seed=42)\n",
    "test_dataset  = second_split[\"train\"]     # ~15%\n",
    "valid_dataset   = second_split[\"test\"]      # ~15%  （后面会被覆盖，和你 pandas 逻辑一致）\n",
    "\n",
    "ds_splits = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"valid\": valid_dataset,\n",
    "    \"test\":  test_dataset,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:56:34.179507Z",
     "iopub.status.busy": "2025-12-09T02:56:34.179379Z",
     "iopub.status.idle": "2025-12-09T02:56:34.182291Z",
     "shell.execute_reply": "2025-12-09T02:56:34.181627Z",
     "shell.execute_reply.started": "2025-12-09T02:56:34.179494Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "# test_data, val_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "# train_data,_ = train_test_split(train_data, train_size=0.1, random_state=42)\n",
    "# test_data, val_data = train_test_split(test_data, train_size=0.1, random_state=42)\n",
    "# val_data, _ = train_test_split(val_data, train_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:56:34.182935Z",
     "iopub.status.busy": "2025-12-09T02:56:34.182826Z",
     "iopub.status.idle": "2025-12-09T02:56:34.186728Z",
     "shell.execute_reply": "2025-12-09T02:56:34.186106Z",
     "shell.execute_reply.started": "2025-12-09T02:56:34.182926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      " Dataset({\n",
      "    features: ['repo', 'commit', 'labels', 'msgs', 'diffs', 'feature', 'text', 'user'],\n",
      "    num_rows: 1781\n",
      "})\n",
      "After\n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['repo', 'commit', 'labels', 'msgs', 'diffs', 'feature', 'text', 'user'],\n",
      "        num_rows: 1246\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['repo', 'commit', 'labels', 'msgs', 'diffs', 'feature', 'text', 'user'],\n",
      "        num_rows: 268\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['repo', 'commit', 'labels', 'msgs', 'diffs', 'feature', 'text', 'user'],\n",
      "        num_rows: 267\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(\"Before:\\n\", full_dataset)\n",
    "print(\"After\\n\", ds_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:56:34.187248Z",
     "iopub.status.busy": "2025-12-09T02:56:34.187144Z",
     "iopub.status.idle": "2025-12-09T02:56:34.190390Z",
     "shell.execute_reply": "2025-12-09T02:56:34.189879Z",
     "shell.execute_reply.started": "2025-12-09T02:56:34.187239Z"
    }
   },
   "outputs": [],
   "source": [
    "# int_to_str = {0:'0', 1:'1'}\n",
    "\n",
    "# prefix = \"Please check whether the tweet is about a real disaster or not: \"\n",
    "\n",
    "# Define the preprocessing function\n",
    "\n",
    "def preprocess_function(examples):\n",
    "   \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "   # The \"inputs\" are the tokenized answer:\n",
    "   inputs = examples[\"text\"]\n",
    "   model_inputs = tokenizer(inputs, max_length=128, padding=True, truncation=True)\n",
    "    \n",
    "   labels = tokenizer(text_target=examples[\"labels\"], padding=True, truncation=True)\n",
    "   model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "   return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:56:34.191042Z",
     "iopub.status.busy": "2025-12-09T02:56:34.190931Z",
     "iopub.status.idle": "2025-12-09T02:57:02.052249Z",
     "shell.execute_reply": "2025-12-09T02:57:02.051480Z",
     "shell.execute_reply.started": "2025-12-09T02:56:34.191032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238e9ac1d4434ede897feb884c18bb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1246 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cba0b2d26a45e9bed903f4360621f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66fd0def5cd440a8debf6c40f8213a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map the preprocessing function across our dataset\n",
    "tokenized_dataset = ds_splits.map(preprocess_function, batched=False, remove_columns=['text','labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation using ROGUE Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:57:02.053070Z",
     "iopub.status.busy": "2025-12-09T02:57:02.052940Z",
     "iopub.status.idle": "2025-12-09T02:57:02.057749Z",
     "shell.execute_reply": "2025-12-09T02:57:02.057096Z",
     "shell.execute_reply.started": "2025-12-09T02:57:02.053059Z"
    }
   },
   "outputs": [],
   "source": [
    "# nltk.download(\"punkt\", quiet=True)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "str_to_int = {'Adaptive':0, 'Corrective':1, 'Perfective':2}\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # 替换 label 中的 -100 为 pad，避免 decode 出错\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    # 解码成字符串\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # 去掉首尾空格\n",
    "    decoded_preds = [p.strip() for p in decoded_preds]\n",
    "    decoded_labels = [l.strip() for l in decoded_labels]\n",
    "\n",
    "    # string → int (positive / negative)\n",
    "    y_pred = [str_to_int.get(p, -1) for p in decoded_preds]\n",
    "    y_true = [str_to_int.get(l, -1) for l in decoded_labels]\n",
    "\n",
    "    # 计算四个指标\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:57:02.058322Z",
     "iopub.status.busy": "2025-12-09T02:57:02.058208Z",
     "iopub.status.idle": "2025-12-09T02:57:02.417955Z",
     "shell.execute_reply": "2025-12-09T02:57:02.417321Z",
     "shell.execute_reply.started": "2025-12-09T02:57:02.058311Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Global Parameters\n",
    "L_RATE = 3e-4\n",
    "BATCH_SIZE = 32\n",
    "PER_DEVICE_EVAL_BATCH = 8\n",
    "WEIGHT_DECAY = 0.01\n",
    "SAVE_TOTAL_LIM = 3\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "   output_dir=\"./results\",\n",
    "   eval_strategy=\"epoch\",\n",
    "   learning_rate=L_RATE,\n",
    "   per_device_train_batch_size=BATCH_SIZE,\n",
    "   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n",
    "   weight_decay=WEIGHT_DECAY,\n",
    "   save_total_limit=SAVE_TOTAL_LIM,\n",
    "   num_train_epochs=NUM_EPOCHS,\n",
    "   predict_with_generate=True,\n",
    "   push_to_hub=False,\n",
    "   logging_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T02:57:02.418581Z",
     "iopub.status.busy": "2025-12-09T02:57:02.418464Z",
     "iopub.status.idle": "2025-12-09T02:57:02.662284Z",
     "shell.execute_reply": "2025-12-09T02:57:02.661528Z",
     "shell.execute_reply.started": "2025-12-09T02:57:02.418569Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3050/2420821063.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_dataset[\"train\"],\n",
    "   eval_dataset=tokenized_dataset[\"test\"],\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-12-09T03:08:58.974Z",
     "iopub.execute_input": "2025-12-09T02:57:02.663027Z",
     "iopub.status.busy": "2025-12-09T02:57:02.662716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='275' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [275/390 00:55 < 00:23, 4.89 it/s, Epoch 7.03/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.314510</td>\n",
       "      <td>0.415730</td>\n",
       "      <td>0.367430</td>\n",
       "      <td>0.423004</td>\n",
       "      <td>0.316986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252205</td>\n",
       "      <td>0.419476</td>\n",
       "      <td>0.276980</td>\n",
       "      <td>0.419978</td>\n",
       "      <td>0.333806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.228487</td>\n",
       "      <td>0.516854</td>\n",
       "      <td>0.653766</td>\n",
       "      <td>0.497441</td>\n",
       "      <td>0.477721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.239595</td>\n",
       "      <td>0.430712</td>\n",
       "      <td>0.395936</td>\n",
       "      <td>0.440781</td>\n",
       "      <td>0.340719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.248345</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.634936</td>\n",
       "      <td>0.568694</td>\n",
       "      <td>0.480303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.210336</td>\n",
       "      <td>0.677903</td>\n",
       "      <td>0.688826</td>\n",
       "      <td>0.690530</td>\n",
       "      <td>0.677242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.161429</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.767265</td>\n",
       "      <td>0.762306</td>\n",
       "      <td>0.763988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T03:07:10.611297Z",
     "iopub.status.busy": "2025-12-09T03:07:10.610705Z",
     "iopub.status.idle": "2025-12-09T03:07:12.949261Z",
     "shell.execute_reply": "2025-12-09T03:07:12.948646Z",
     "shell.execute_reply.started": "2025-12-09T03:07:10.611248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.16809788346290588,\n",
       " 'eval_accuracy': 0.8134328358208955,\n",
       " 'eval_precision': 0.8145611937155449,\n",
       " 'eval_recall': 0.8143576156211338,\n",
       " 'eval_f1': 0.8134502923976609,\n",
       " 'eval_runtime': 2.3249,\n",
       " 'eval_samples_per_second': 115.275,\n",
       " 'eval_steps_per_second': 14.624,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_metrics = trainer.evaluate(eval_dataset=tokenized_dataset[\"valid\"])\n",
    "fewshot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
